{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "048cdaae",
   "metadata": {},
   "source": [
    "# 02 â€” Explore results and what-ifs\n",
    "\n",
    "This exploratory notebook evaluates the trained model's behaviour, visualises distributional trends, and applies scenario analyses with confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bae9e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a555a87",
   "metadata": {},
   "source": [
    "## Load marts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a51ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('data/marts')\n",
    "FACT_DAY_PATH = DATA_DIR / 'sydney_day_samples.csv'\n",
    "SCENARIO_PATH = DATA_DIR / 'what_if_scenarios.csv'\n",
    "df = pd.read_csv(FACT_DAY_PATH, parse_dates=['date'])\n",
    "scenarios = pd.read_csv(SCENARIO_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0ceb8f",
   "metadata": {},
   "source": [
    "## Daily trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f1a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_summary = (\n",
    "    df.assign(weekday=df['weekday'].astype('category'))\n",
    "      .groupby('weekday')\n",
    "      [['mood_score', 'weather_temp_c', 'beach_time_hours', 'commute_minutes']]\n",
    "      .mean()\n",
    "      .sort_index()\n",
    ")\n",
    "daily_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dc0c5d",
   "metadata": {},
   "source": [
    "The averages show how mood aligns with the typical weekday rhythm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8039b005",
   "metadata": {},
   "source": [
    "## Refit the pipeline for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ff3c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['weekday', 'weather_temp_c', 'harbour_visits', 'beach_time_hours', 'commute_minutes', 'cultural_events']\n",
    "target = 'mood_score'\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), ['weekday']),\n",
    "        ('num', StandardScaler(), ['weather_temp_c', 'harbour_visits', 'beach_time_hours', 'commute_minutes', 'cultural_events']),\n",
    "    ]\n",
    ")\n",
    "model = Pipeline(steps=[('prep', preprocessor), ('regressor', LinearRegression())])\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03108611",
   "metadata": {},
   "source": [
    "## Confidence intervals for recent days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5209c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_interval(pipeline, features, target, samples=300, alpha=0.05, random_state=13):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    preds = []\n",
    "    for _ in range(samples):\n",
    "        idx = rng.integers(0, len(features), len(features))\n",
    "        X_s = features.iloc[idx]\n",
    "        y_s = target.iloc[idx]\n",
    "        pipeline.fit(X_s, y_s)\n",
    "        preds.append(pipeline.predict(features))\n",
    "    preds = np.vstack(preds)\n",
    "    point = pipeline.fit(features, target).predict(features)\n",
    "    lower = np.percentile(preds, 100 * alpha / 2, axis=0)\n",
    "    upper = np.percentile(preds, 100 * (1 - alpha / 2), axis=0)\n",
    "    return point, lower, upper\n",
    "\n",
    "recent = df.tail(7).copy()\n",
    "point, lower, upper = bootstrap_interval(model, X, y)\n",
    "recent['prediction'] = point[-7:]\n",
    "recent['lower_ci'] = lower[-7:]\n",
    "recent['upper_ci'] = upper[-7:]\n",
    "recent[['date', 'weekday', 'mood_score', 'prediction', 'lower_ci', 'upper_ci']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5a7e62",
   "metadata": {},
   "source": [
    "## Scenario-based sensitivity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7207e265",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = df[features].mean(numeric_only=True).to_dict()\n",
    "baseline['weekday'] = df['weekday'].mode().iat[0]\n",
    "baseline_df = pd.DataFrame([baseline])\n",
    "baseline_prediction = model.predict(baseline_df)[0]\n",
    "scenario_rows = []\n",
    "for _, row in scenarios.iterrows():\n",
    "    scenario_features = baseline_df.copy()\n",
    "    scenario_features['weather_temp_c'] += row['delta_weather_temp_c']\n",
    "    scenario_features['beach_time_hours'] += row['delta_beach_time_hours']\n",
    "    scenario_features['commute_minutes'] += row['delta_commute_minutes']\n",
    "    scenario_features['cultural_events'] += row['delta_cultural_events']\n",
    "    prediction = model.predict(scenario_features)[0]\n",
    "    scenario_rows.append({\n",
    "        'scenario': row['scenario'],\n",
    "        'description': row['description'],\n",
    "        'predicted_mood': prediction,\n",
    "        'delta_vs_baseline': prediction - baseline_prediction\n",
    "    })\n",
    "scenario_results = pd.DataFrame(scenario_rows)\n",
    "scenario_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a00834",
   "metadata": {},
   "source": [
    "Scenario deltas provide an actionable way to communicate how changes in weather, leisure, or commute patterns influence predicted mood."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
