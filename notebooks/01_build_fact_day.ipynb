{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e90020c",
   "metadata": {},
   "source": [
    "# 01 \u2014 Build the fact of a Sydney day\n",
    "\n",
    "This notebook demonstrates how to build a simple regression model for the synthetic Sydney day dataset.\n",
    "\n",
    "Steps include:\n",
    "\n",
    "1. Loading the synthetic mart generated via `make ingest && make marts && make analyze`.\n",
    "2. Performing light feature engineering.\n",
    "3. Training a linear regression model.\n",
    "4. Generating predictions with bootstrap confidence intervals.\n",
    "5. Running a simple sensitivity analysis to understand the impact of feature changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\ud83d\udca1 **Rebuild the mart before running the notebook**\n",
    "\n",
    "```bash\n",
    "make ingest && make marts && make analyze\n",
    "```\n",
    "\n",
    "The commands write synthetic raw inputs, rebuild `data/marts/fact_day.parquet`, and refresh supporting quality reports so the analysis always reflects the latest ingest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac85f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc2d0e6",
   "metadata": {},
   "source": [
    "## Load the mart and inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60308de",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path(os.environ.get('OPAL_OCEAN_PROJECT_ROOT', Path.cwd()))\n",
    "MARTS_DIR = Path(os.environ.get('OPAL_OCEAN_MARTS_DIR', PROJECT_ROOT / 'data' / 'marts'))\n",
    "FACT_DAY_PATH = MARTS_DIR / 'fact_day.parquet'\n",
    "if not FACT_DAY_PATH.exists():\n",
    "    raise FileNotFoundError('Run `make ingest && make marts && make analyze` to build data/marts/fact_day.parquet.')\n",
    "\n",
    "df = pd.read_parquet(FACT_DAY_PATH)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "if 'beach_ok' in df.columns:\n",
    "    df['beach_ok'] = df['beach_ok'].astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1837aa62",
   "metadata": {},
   "source": [
    "### Feature overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f402daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d167b31",
   "metadata": {},
   "source": [
    "## Split features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65583ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'mood_1_5'\n",
    "features = [\n",
    "    'weekday',\n",
    "    'commute_minutes',\n",
    "    'opal_cost',\n",
    "    'reliability',\n",
    "    'pm25_mean',\n",
    "    'rain_24h_mm',\n",
    "    'beach_ok',\n",
    "    'steps',\n",
    "    'sleep_hours',\n",
    "    'caffeine_mg',\n",
    "]\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2685071f",
   "metadata": {},
   "source": [
    "## Build the modeling pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215c3542",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['weekday']\n",
    "numeric_features = [col for col in features if col not in categorical_features]\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "    ]\n",
    ")\n",
    "model = Pipeline(steps=[('prep', preprocessor), ('regressor', LinearRegression())])\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b06bd2",
   "metadata": {},
   "source": [
    "## Evaluate on the hold-out set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e2a2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print('R^2:', r2_score(y_test, y_pred))\n",
    "print('MAE:', mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2f3452",
   "metadata": {},
   "source": [
    "## Bootstrap prediction intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970a76e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_prediction_interval(pipeline, features, target, samples=200, alpha=0.05, random_state=42):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    preds = []\n",
    "    X = features.to_numpy()\n",
    "    y = target.to_numpy()\n",
    "    n = len(features)\n",
    "    for _ in range(samples):\n",
    "        idx = rng.integers(0, n, size=n)\n",
    "        X_sample = features.iloc[idx]\n",
    "        y_sample = target.iloc[idx]\n",
    "        pipeline.fit(X_sample, y_sample)\n",
    "        preds.append(pipeline.predict(features))\n",
    "    preds = np.vstack(preds)\n",
    "    lower = np.percentile(preds, 100 * alpha / 2, axis=0)\n",
    "    upper = np.percentile(preds, 100 * (1 - alpha / 2), axis=0)\n",
    "    point = pipeline.fit(features, target).predict(features)\n",
    "    return point, lower, upper\n",
    "\n",
    "point_pred, lower_ci, upper_ci = bootstrap_prediction_interval(model, X_train, y_train)\n",
    "intervals = pd.DataFrame({\n",
    "    'date': df.loc[X_train.index, 'date'],\n",
    "    'point_pred': point_pred,\n",
    "    'lower_ci': lower_ci,\n",
    "    'upper_ci': upper_ci\n",
    "}).reset_index(drop=True)\n",
    "intervals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c30336e",
   "metadata": {},
   "source": [
    "## Sensitivity analysis\n",
    "\n",
    "We assess how marginal changes in each feature affect the predicted mood score by perturbing one feature at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d45772",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = X_train.mean(numeric_only=True).to_dict()\n",
    "baseline['weekday'] = X_train['weekday'].mode().iat[0]\n",
    "baseline_df = pd.DataFrame([baseline])\n",
    "baseline_prediction = model.predict(baseline_df)[0]\n",
    "results = []\n",
    "perturbations = {\n",
    "    'commute_minutes': [-20, 20],\n",
    "    'reliability': [-0.2, 0.2],\n",
    "    'pm25_mean': [-5, 5],\n",
    "    'rain_24h_mm': [-10, 10],\n",
    "    'steps': [-1500, 1500],\n",
    "    'sleep_hours': [-1.0, 1.0],\n",
    "    'caffeine_mg': [-100, 100],\n",
    "}\n",
    "for feature, deltas in perturbations.items():\n",
    "    for delta in deltas:\n",
    "        scenario = baseline_df.copy()\n",
    "        if feature == 'reliability':\n",
    "            scenario[feature] = (scenario[feature] + delta).clip(0.0, 1.0)\n",
    "        else:\n",
    "            scenario[feature] = scenario[feature] + delta\n",
    "        prediction = model.predict(scenario)[0]\n",
    "        results.append({\n",
    "            'feature': feature,\n",
    "            'delta': delta,\n",
    "            'prediction': prediction,\n",
    "            'change_vs_baseline': prediction - baseline_prediction\n",
    "        })\n",
    "sensitivity_df = pd.DataFrame(results)\n",
    "sensitivity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30238751",
   "metadata": {},
   "source": [
    "The sensitivity table shows how each variable shifts the predicted mood score relative to the average training day."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}